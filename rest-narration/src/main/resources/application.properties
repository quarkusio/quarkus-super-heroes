quarkus.application.name=rest-narration
quarkus.banner.path=banner.txt

## Default OpenAI configuration
quarkus.langchain4j.chat-model.provider=openai
quarkus.langchain4j.image-model.provider=openai
quarkus.langchain4j.dalle3.image-model.provider=openai

quarkus.langchain4j.openai.enable-integration=false
quarkus.langchain4j.openai.api-key=change-me
quarkus.langchain4j.openai.embedding-model.enabled=false
quarkus.langchain4j.openai.moderation-model.enabled=false
quarkus.langchain4j.openai.timeout=60s
quarkus.langchain4j.openai.max-retries=3
quarkus.langchain4j.openai.chat-model.temperature=0.7
quarkus.langchain4j.openai.chat-model.top-p=0.5
quarkus.langchain4j.openai.dalle3.enable-integration=${quarkus.langchain4j.openai.enable-integration}
quarkus.langchain4j.openai.dalle3.api-key=${quarkus.langchain4j.openai.api-key}
quarkus.langchain4j.openai.dalle3.embedding-model.enabled=${quarkus.langchain4j.openai.embedding-model.enabled}
quarkus.langchain4j.openai.dalle3.moderation-model.enabled=${quarkus.langchain4j.openai.moderation-model.enabled}
quarkus.langchain4j.openai.dalle3.timeout=${quarkus.langchain4j.openai.timeout}
quarkus.langchain4j.openai.dalle3.max-retries=${quarkus.langchain4j.openai.max-retries}
quarkus.langchain4j.openai.dalle3.chat-model.temperature=${quarkus.langchain4j.openai.chat-model.temperature}
quarkus.langchain4j.openai.dalle3.chat-model.top-p=${quarkus.langchain4j.openai.chat-model.top-p}

## Default Azure OpenAI configuration
quarkus.langchain4j.azure-openai.enable-integration=false
quarkus.langchain4j.azure-openai.api-key=change-me
quarkus.langchain4j.azure-openai.embedding-model.enabled=false
quarkus.langchain4j.azure-openai.moderation-model.enabled=false
quarkus.langchain4j.azure-openai.resource-name=cs-super-heroes
quarkus.langchain4j.azure-openai.deployment-name=csdeploy-super-heroes
quarkus.langchain4j.azure-openai.timeout=15s
quarkus.langchain4j.azure-openai.max-retries=3
quarkus.langchain4j.azure-openai.chat-model.temperature=${quarkus.langchain4j.openai.chat-model.temperature}
quarkus.langchain4j.azure-openai.chat-model.top-p=${quarkus.langchain4j.openai.chat-model.top-p}
quarkus.langchain4j.azure-openai.dalle3.enable-integration=${quarkus.langchain4j.azure-openai.enable-integration}
quarkus.langchain4j.azure-openai.dalle3.api-key=${quarkus.langchain4j.azure-openai.api-key}
quarkus.langchain4j.azure-openai.dalle3.api-version=2024-02-15-preview
quarkus.langchain4j.azure-openai.dalle3.embedding-model.enabled=${quarkus.langchain4j.azure-openai.embedding-model.enabled}
quarkus.langchain4j.azure-openai.dalle3.moderation-model.enabled=${quarkus.langchain4j.azure-openai.moderation-model.enabled}
quarkus.langchain4j.azure-openai.dalle3.resource-name=${quarkus.langchain4j.azure-openai.resource-name}
quarkus.langchain4j.azure-openai.dalle3.deployment-name=Dalle3
quarkus.langchain4j.azure-openai.dalle3.timeout=${quarkus.langchain4j.azure-openai.timeout}
quarkus.langchain4j.azure-openai.dalle3.max-retries=${quarkus.langchain4j.azure-openai.max-retries}

## OpenAI profile configuration (in dev mode, make live calls to OpenAI by setting -Dquarkus.profile=openai)
%dev,test,openai.quarkus.langchain4j.chat-model.provider=openai
%dev,test,openai.quarkus.langchain4j.image-model.provider=openai
%dev,test,openai.quarkus.langchain4j.dalle3.image-model.provider=openai
%dev,test.quarkus.langchain4j.openai.base-url=http://localhost:${quarkus.wiremock.devservices.port}/v1/
%dev,test.quarkus.langchain4j.openai.timeout=3s
%dev,test,openai,azure-openai.quarkus.langchain4j.openai.enable-integration=true
%dev,test,openai,azure-openai.quarkus.langchain4j.openai.log-requests=true
%dev,test,openai,azure-openai.quarkus.langchain4j.openai.log-responses=true
%dev,test.quarkus.langchain4j.openai.max-retries=2
%openai.quarkus.langchain4j.openai.base-url=https://api.openai.com/v1/
%dev,test.quarkus.langchain4j.openai.dalle3.base-url=${%dev,test.quarkus.langchain4j.openai.base-url}
%dev,test.quarkus.langchain4j.openai.dalle3.timeout=${%dev,test.quarkus.langchain4j.openai.timeout}
%dev,test,openai,azure-openai.quarkus.langchain4j.openai.dalle3.enable-integration=${%dev,test,openai,azure-openai.quarkus.langchain4j.openai.enable-integration}
%dev,test,openai,azure-openai.quarkus.langchain4j.openai.dalle3.log-requests=${%dev,test,openai,azure-openai.quarkus.langchain4j.openai.log-requests}
%dev,test,openai,azure-openai.quarkus.langchain4j.openai.dalle3.log-responses=${%dev,test,openai,azure-openai.quarkus.langchain4j.openai.log-responses}
%dev,test.quarkus.langchain4j.openai.dalle3.max-retries=${%dev,test.quarkus.langchain4j.openai.max-retries}
%openai.quarkus.langchain4j.openai.dalle3.base-url=${%openai.quarkus.langchain4j.openai.base-url}

## Azure OpenAI Profile configuration (in dev mode, make live calls to Azure OpenAI by setting -Dquarkus.profile=azure-openai)
%azure-openai.quarkus.langchain4j.chat-model.provider=azure-openai
%azure-openai.quarkus.langchain4j.image-model.provider=azure-openai
%azure-openai.quarkus.langchain4j.dalle3.image-model.provider=azure-openai
%dev,test.quarkus.langchain4j.azure-openai.endpoint=http://localhost:${quarkus.wiremock.devservices.port}/v1/
%dev,test,quarkus.langchain4j.azure-openai.timeout=3s
%dev,test,openai,azure-openai.quarkus.langchain4j.azure-openai.enable-integration=true
%dev,test,openai,azure-openai.quarkus.langchain4j.azure-openai.log-requests=true
%dev,test,openai,azure-openai.quarkus.langchain4j.azure-openai.log-responses=true
%dev,test.quarkus.langchain4j.azure-openai.max-retries=2
%dev,test.quarkus.langchain4j.azure-openai.dalle3.endpoint=${%dev,test.quarkus.langchain4j.azure-openai.endpoint}
%dev,test,quarkus.langchain4j.azure-openai.dalle3.timeout=${%dev,test,quarkus.langchain4j.azure-openai.timeout}
%dev,test,openai,azure-openai.quarkus.langchain4j.azure-openai.dalle3.enable-integration=${%dev,test,openai,azure-openai.quarkus.langchain4j.azure-openai.enable-integration}
%dev,test,openai,azure-openai.quarkus.langchain4j.azure-openai.dalle3.log-requests=${%dev,test,openai,azure-openai.quarkus.langchain4j.azure-openai.log-requests}
%dev,test,openai,azure-openai.quarkus.langchain4j.azure-openai.dalle3.log-responses=${%dev,test,openai,azure-openai.quarkus.langchain4j.azure-openai.log-responses}
%dev,test.quarkus.langchain4j.azure-openai.dalle3.max-retries=${%dev,test.quarkus.langchain4j.azure-openai.max-retries}

## WireMock configuration
# Disable it when making live calls to openai/azure openai
%openai,azure-openai.quarkus.wiremock.devservices.enabled=false
%dev,test.quarkus.wiremock.devservices.files-mapping=src/test/resources/wiremock

## HTTP configuration
quarkus.http.port=8087
quarkus.http.test-port=0
quarkus.jackson.serialization-inclusion=non-empty

## Logging configuration
quarkus.log.category."io.quarkus.sample.superheroes".level=DEBUG
quarkus.log.level=INFO
quarkus.log.console.format=%d{HH:mm:ss} %-5p traceId=%X{traceId}, parentId=%X{parentId}, spanId=%X{spanId}, sampled=%X{sampled} [%c{2.}] (%t) %s%e%n
quarkus.log.console.level=INFO
quarkus.log.console.darken=1
%dev,test,openai,azure-openai.quarkus.log.console.format=%d{HH:mm:ss} %-5p [%c{2.}] (%t) %s%e%n
%dev,test,openai,azure-openai.quarkus.log.console.level=DEBUG

# OpenTelemetry
quarkus.otel.resource.attributes=app=${quarkus.application.name},application=narration-service,system=quarkus-super-heroes
quarkus.otel.exporter.otlp.traces.endpoint=http://localhost:4317

## CORS
quarkus.http.cors=true
quarkus.http.cors.origins=*

# OpenAPI
quarkus.smallrye-openapi.info-title=Narration API
quarkus.smallrye-openapi.info-description=This API allows Narration using the Microsoft Semantic Kernel OpenAI
quarkus.smallrye-openapi.info-version=1.0
quarkus.smallrye-openapi.info-contact-name=Quarkus
quarkus.smallrye-openapi.info-contact-url=https://github.com/quarkusio
quarkus.swagger-ui.always-include=true

# Container image
quarkus.container-image.builder=docker
quarkus.container-image.registry=quay.io
quarkus.container-image.group=quarkus-super-heroes
quarkus.container-image.name=${quarkus.application.name}

# Kubernetes
%kubernetes.quarkus.config.profile.parent=prod
%kubernetes.quarkus.kubernetes.deployment-target=kubernetes
quarkus.kubernetes.part-of=narration-service
quarkus.kubernetes.annotations."app.openshift.io/connects-to"=otel-collector
quarkus.kubernetes.env.configmaps=${quarkus.application.name}-config
quarkus.kubernetes.labels.app=${quarkus.application.name}
quarkus.kubernetes.labels.application=${quarkus.kubernetes.part-of}
quarkus.kubernetes.labels.system=quarkus-super-heroes

# OpenShift
%openshift.quarkus.config.profile.parent=prod
%openshift.quarkus.kubernetes.deployment-target=openshift
%openshift.quarkus.container-image.builder=openshift
quarkus.openshift.base-jvm-image=registry.access.redhat.com/ubi9/openjdk-17:1.17
quarkus.openshift.base-native-image=quay.io/quarkus/ubi-quarkus-native-binary-s2i:2.0
quarkus.openshift.deployment-kind=deployment
quarkus.openshift.route.expose=true
quarkus.openshift.route.tls.termination=edge
quarkus.openshift.route.tls.insecure-edge-termination-policy=Redirect
quarkus.openshift.annotations."app.openshift.io/connects-to"=otel-collector
quarkus.openshift.labels.app=${quarkus.kubernetes.labels.app}
quarkus.openshift.labels.application=${quarkus.kubernetes.labels.application}
quarkus.openshift.labels.system=${quarkus.kubernetes.labels.system}

# Knative
%knative.quarkus.config.profile.parent=prod
%knative.quarkus.kubernetes.deployment-target=knative
quarkus.knative.annotations."app.openshift.io/connects-to"=otel-collector
quarkus.knative.labels.app=${quarkus.kubernetes.labels.app}
quarkus.knative.labels.application=${quarkus.kubernetes.labels.application}
quarkus.knative.labels.system=${quarkus.kubernetes.labels.system}

# Knative on OpenShift
%knative-openshift.quarkus.config.profile.parent=knative
%knative-openshift.quarkus.container-image.builder=openshift

# Minikube
%minikube.quarkus.config.profile.parent=prod
%minikube.quarkus.kubernetes.deployment-target=minikube
